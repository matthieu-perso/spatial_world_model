{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FHti9UF3I22i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement google-colab (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for google-colab\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title installs\n",
        "!pip install -q optuna\n",
        "!pip install -q google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdd_e9CgI_aY",
        "outputId": "e6bbfaa2-0f2f-4fb1-be43-17b1a9525013"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      8\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "#@title imports\n",
        "\n",
        "import h5py\n",
        "import re\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from typing import Dict\n",
        "\n",
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a_Js4FBrJAyZ"
      },
      "outputs": [],
      "source": [
        "#@title utils\n",
        "\n",
        "# ===================\n",
        "# function: load data\n",
        "# ===================\n",
        "def load_data(hdf5_path: str, verbose: bool=True) -> Dict:\n",
        "    \"\"\"\n",
        "    load data from hdf5 file\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    print(\"loading data from HDF5 file...\")\n",
        "\n",
        "    with h5py.File(hdf5_path, \"r\") as f:\n",
        "        # load the sentences\n",
        "        sentences = [s.decode('utf-8') for s in f[\"sentences\"][:]]\n",
        "\n",
        "        # load embeddings for each layer\n",
        "        layer_8 = torch.tensor(f[\"layer_8\"][:], dtype=torch.float32)\n",
        "        layer_16 = torch.tensor(f[\"layer_16\"][:], dtype=torch.float32)\n",
        "        layer_24 = torch.tensor(f[\"layer_24\"][:], dtype=torch.float32)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Loaded {len(sentences)} sentences and their embeddings\")\n",
        "        print(f\"Layer 8 embeddings shape: {layer_8.shape}\")\n",
        "        print(f\"Layer 16 embeddings shape: {layer_16.shape}\")\n",
        "        print(f\"Layer 24 embeddings shape: {layer_24.shape}\")\n",
        "        print(f\"Data loading completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    return {\"sentences\": sentences, \"layer_8\": layer_8, \"layer_16\": layer_16, \"layer_24\": layer_24}\n",
        "\n",
        "# =========================\n",
        "# function: parse sentences\n",
        "# =========================\n",
        "def parse_sentences(sentences: list, verbose: bool=True) -> None:\n",
        "    \"\"\"\n",
        "    parse sentences\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    print(\"parsing sentences into triplets...\")\n",
        "\n",
        "    # primary pattern for \"The X is Y the Z.\" format\n",
        "    pattern = r\"The (.*?) is (.*?) the (.*?)\\.\"\n",
        "\n",
        "    triplets = []\n",
        "    valid_indices = []\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        match = re.search(pattern, sentence)\n",
        "        if match:\n",
        "            obj1, relation, obj2 = match.groups()\n",
        "            triplets.append((obj1.strip(), relation.strip(), obj2.strip()))\n",
        "            valid_indices.append(i)\n",
        "        else:\n",
        "            # secondary pattern for relations without \"the\" (like \"on\", \"facing\")\n",
        "            # look for patterns like \"The table is on the chair.\" or \"The table is facing the lamp.\"\n",
        "            alt_pattern = r\"The (.*?) is (.*) (chair|lamp|table)\\.\"\n",
        "            match = re.search(alt_pattern, sentence)\n",
        "            if match:\n",
        "                obj1, relation, obj2 = match.groups()\n",
        "                triplets.append((obj1.strip(), relation.strip(), obj2.strip()))\n",
        "                valid_indices.append(i)\n",
        "            else:\n",
        "                # last attempt with very general pattern\n",
        "                try:\n",
        "                    # split the sentence\n",
        "                    # \"The table is connected to the lamp.\" → [\"The\", \"table\", \"is\", \"connected\", \"to\", \"the\", \"lamp.\"]\n",
        "                    words = sentence.split()\n",
        "                    if len(words) >= 5 and words[0].lower() == \"the\" and words[2].lower() == \"is\":\n",
        "                        obj1 = words[1]\n",
        "\n",
        "                        # find the last occurrence of \"the\" to locate obj2\n",
        "                        if \"the\" in words[3:]:\n",
        "                            last_the_idx = len(words) - 1 - words[::-1].index(\"the\")\n",
        "                            obj2 = words[last_the_idx+1].rstrip('.')\n",
        "                            relation = \" \".join(words[3:last_the_idx])\n",
        "                            triplets.append((obj1.strip(), relation.strip(), obj2.strip()))\n",
        "                            valid_indices.append(i)\n",
        "                        else:\n",
        "                            # if no \"the\" found, assume the last word is the object\n",
        "                            obj2 = words[-1].rstrip('.')\n",
        "                            relation = \" \".join(words[3:-1])\n",
        "                            triplets.append((obj1.strip(), relation.strip(), obj2.strip()))\n",
        "                            valid_indices.append(i)\n",
        "                    else:\n",
        "                        print(f\"Failed to parse: {sentence}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing: {sentence}, Error: {e}\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Successfully parsed {len(triplets)} triplets\")\n",
        "        print(f\"Parsing completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "        # Display a few parsed triplets for verification\n",
        "        print(\"\\nSample triplets:\")\n",
        "        for i in range(min(5, len(triplets))):\n",
        "            print(f\"{i}: {triplets[i]}\")\n",
        "\n",
        "    return {\"triplets\": triplets, \"valid_indices\": valid_indices}\n",
        "\n",
        "\n",
        "# =========================\n",
        "# function: encode triplets\n",
        "# =========================\n",
        "def encode_triplets(triplets, verbose=True):\n",
        "    \"\"\"\n",
        "    encode triplets for model training\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    print(\"Encoding triplets...\")\n",
        "\n",
        "    # extract separate components\n",
        "    objects1, relations, objects2 = zip(*triplets)\n",
        "\n",
        "    # filter out empty strings\n",
        "    objects1 = [obj if obj else \"UNKNOWN\" for obj in objects1]\n",
        "    relations = [rel if rel else \"UNKNOWN\" for rel in relations]\n",
        "    objects2 = [obj if obj else \"UNKNOWN\" for obj in objects2]\n",
        "\n",
        "    # encode each component\n",
        "    obj1_encoder = LabelEncoder()\n",
        "    rel_encoder = LabelEncoder()\n",
        "    obj2_encoder = LabelEncoder()\n",
        "\n",
        "    obj1_labels = obj1_encoder.fit_transform(objects1)\n",
        "    rel_labels = rel_encoder.fit_transform(relations)\n",
        "    obj2_labels = obj2_encoder.fit_transform(objects2)\n",
        "\n",
        "    labels = {\"object_1\": obj1_labels, \"relation\": rel_labels, \"object_2\": obj2_labels}\n",
        "\n",
        "    # create mapping dictionaries for later analysis\n",
        "    obj1_mapping = dict(zip(obj1_encoder.classes_, range(len(obj1_encoder.classes_))))\n",
        "    rel_mapping = dict(zip(rel_encoder.classes_, range(len(rel_encoder.classes_))))\n",
        "    obj2_mapping = dict(zip(obj2_encoder.classes_, range(len(obj2_encoder.classes_))))\n",
        "\n",
        "    mappings = {\"object_1\": obj1_mapping, \"relation\": rel_mapping, \"object_2\": obj2_mapping}\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Found {len(obj1_mapping)} unique objects as subject\")\n",
        "        print(f\"Found {len(rel_mapping)} unique relations\")\n",
        "        print(f\"Found {len(obj2_mapping)} unique objects as object\")\n",
        "\n",
        "        # Print some of the unique relations\n",
        "        print(\"\\nSample relations:\")\n",
        "        sample_relations = list(rel_mapping.keys())[:10]\n",
        "        for i, rel in enumerate(sample_relations):\n",
        "            print(f\"{i}: {rel}\")\n",
        "\n",
        "        print(f\"Encoding completed in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "    return labels, mappings\n",
        "\n",
        "\n",
        "# ============================\n",
        "# function: prepare data split\n",
        "# ============================\n",
        "def prepare_data_split(layer_data, valid_indices, labels, test_size=0.2):\n",
        "    \"\"\"\n",
        "    prepare single train/test split for all labels\n",
        "    \"\"\"\n",
        "    # filter embeddings to keep only valid indices\n",
        "    X = layer_data[valid_indices]\n",
        "\n",
        "    # create a single train/test split for all labels\n",
        "    X_train, X_test, y_obj1_train, y_obj1_test, y_rel_train, y_rel_test, y_obj2_train, y_obj2_test = train_test_split(\n",
        "        X,\n",
        "        labels[\"object_1\"],\n",
        "        labels[\"relation\"],\n",
        "        labels[\"object_2\"],\n",
        "        test_size=test_size,\n",
        "        random_state=42\n",
        "        )\n",
        "\n",
        "    # convert to PyTorch tensors\n",
        "    X_train_tensor = X_train.clone().detach().float()\n",
        "    X_test_tensor = X_test.clone().detach().float()\n",
        "\n",
        "    y_obj1_train_tensor = torch.tensor(y_obj1_train, dtype=torch.long)\n",
        "    y_obj1_test_tensor = torch.tensor(y_obj1_test, dtype=torch.long)\n",
        "\n",
        "    y_rel_train_tensor = torch.tensor(y_rel_train, dtype=torch.long)\n",
        "    y_rel_test_tensor = torch.tensor(y_rel_test, dtype=torch.long)\n",
        "\n",
        "    y_obj2_train_tensor = torch.tensor(y_obj2_train, dtype=torch.long)\n",
        "    y_obj2_test_tensor = torch.tensor(y_obj2_test, dtype=torch.long)\n",
        "\n",
        "    return {\n",
        "        'X_train': X_train_tensor,\n",
        "        'X_test': X_test_tensor,\n",
        "        'y_obj1_train': y_obj1_train_tensor,\n",
        "        'y_obj1_test': y_obj1_test_tensor,\n",
        "        'y_rel_train': y_rel_train_tensor,\n",
        "        'y_rel_test': y_rel_test_tensor,\n",
        "        'y_obj2_train': y_obj2_train_tensor,\n",
        "        'y_obj2_test': y_obj2_test_tensor\n",
        "        }\n",
        "\n",
        "# =============================\n",
        "# function: create data loaders\n",
        "# =============================\n",
        "def create_data_loaders(split_data, batch_size=32):\n",
        "    \"\"\"\n",
        "    create data loaders for training and testing\n",
        "    \"\"\"\n",
        "    # create training datasets\n",
        "    train_obj1_dataset = TensorDataset(split_data['X_train'], split_data['y_obj1_train'])\n",
        "    train_rel_dataset = TensorDataset(split_data['X_train'], split_data['y_rel_train'])\n",
        "    train_obj2_dataset = TensorDataset(split_data['X_train'], split_data['y_obj2_train'])\n",
        "\n",
        "    # create test datasets\n",
        "    test_obj1_dataset = TensorDataset(split_data['X_test'], split_data['y_obj1_test'])\n",
        "    test_rel_dataset = TensorDataset(split_data['X_test'], split_data['y_rel_test'])\n",
        "    test_obj2_dataset = TensorDataset(split_data['X_test'], split_data['y_obj2_test'])\n",
        "\n",
        "    # create data loaders\n",
        "    train_obj1_loader = DataLoader(train_obj1_dataset, batch_size=batch_size, shuffle=True)\n",
        "    train_rel_loader = DataLoader(train_rel_dataset, batch_size=batch_size, shuffle=True)\n",
        "    train_obj2_loader = DataLoader(train_obj2_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    test_obj1_loader = DataLoader(test_obj1_dataset, batch_size=batch_size)\n",
        "    test_rel_loader = DataLoader(test_rel_dataset, batch_size=batch_size)\n",
        "    test_obj2_loader = DataLoader(test_obj2_dataset, batch_size=batch_size)\n",
        "\n",
        "    return {\n",
        "        'train': {\n",
        "            'object_1': train_obj1_loader,\n",
        "            'relation': train_rel_loader,\n",
        "            'object_2': train_obj2_loader\n",
        "            },\n",
        "        'test': {\n",
        "            'object_1': test_obj1_loader,\n",
        "            'relation': test_rel_loader,\n",
        "            'object_2': test_obj2_loader\n",
        "            }\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wEaIutejYNUl"
      },
      "outputs": [],
      "source": [
        "#@title nonlinear probe\n",
        "\n",
        "# class: nonlinear probe\n",
        "class MLPProbe(nn.Module):\n",
        "    def __init__(self, input_size: int, depth: int, width: int, output_size: int) -> None:\n",
        "        super(MLPProbe, self).__init__()\n",
        "\n",
        "        # define the layers\n",
        "        layers = []\n",
        "        for k in range(depth):\n",
        "            if k == 0:\n",
        "                layers.append(nn.Linear(input_size, width))\n",
        "            else:\n",
        "                layers.append(nn.Linear(width, width))\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        layers.append(nn.Linear(width, output_size))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6FVxiX1EYw5y"
      },
      "outputs": [],
      "source": [
        "#@title hyper-param tuning via optuna\n",
        "\n",
        "def make_objective(input_dim: int, output_dim: int, train_loader: DataLoader, test_loader: DataLoader, epochs: int = 10):\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "\n",
        "        # set device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # hyper-params to tune\n",
        "        depth = trial.suggest_int(\"depth\", 2, 5)\n",
        "        width = trial.suggest_int(\"width\", 16, 256, log=True)\n",
        "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "        # you can add dropout here later\n",
        "\n",
        "        # define the model, loss, and optimizer\n",
        "        model = MLPProbe(input_dim, depth, width, output_dim)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # training loop\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # move data to device\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # backward pass and optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # track metrics\n",
        "                epoch_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            total_loss = epoch_loss / len(train_loader)\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "        # log to W&B\n",
        "        wandb.log({\n",
        "            \"trial\": trial.number,\n",
        "            \"depth\": depth,\n",
        "            \"width\": width,\n",
        "            \"learning_rate\": learning_rate,\n",
        "            \"loss\": total_loss,\n",
        "            \"accuracy\": accuracy})\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    return objective\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnoM_acMMppg",
        "outputId": "4a129f73-9138-4b4d-d523-fe75ff4eb6ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading data from HDF5 file...\n",
            "Loaded 20000 sentences and their embeddings\n",
            "Layer 8 embeddings shape: torch.Size([20000, 3072])\n",
            "Layer 16 embeddings shape: torch.Size([20000, 3072])\n",
            "Layer 24 embeddings shape: torch.Size([20000, 3072])\n",
            "Data loading completed in 9.10 seconds\n",
            "parsing sentences into triplets...\n",
            "Successfully parsed 20000 triplets\n",
            "Parsing completed in 0.04 seconds\n",
            "\n",
            "Sample triplets:\n",
            "0: ('table', 'over', 'chair')\n",
            "1: ('table', 'on top of', 'chair')\n",
            "2: ('table', 'higher than', 'chair')\n",
            "3: ('table', 'elevated above', 'chair')\n",
            "4: ('table', 'to', 'left of the chair')\n",
            "Encoding triplets...\n",
            "Found 15 unique objects as subject\n",
            "Found 29 unique relations\n",
            "Found 100 unique objects as object\n",
            "\n",
            "Sample relations:\n",
            "0: above\n",
            "1: adjacent to\n",
            "2: ahead of\n",
            "3: at 45 degrees to\n",
            "4: attached to\n",
            "5: before\n",
            "6: beside\n",
            "7: close to\n",
            "8: connected to\n",
            "9: diagonally above-left\n",
            "Encoding completed in 0.06 seconds\n"
          ]
        }
      ],
      "source": [
        "#@title main\n",
        "\n",
        "# load the data\n",
        "VERBOSE = True\n",
        "hdf5_path = \"/content/drive/MyDrive/Llama-3.2-3B-Instruct_layer_embeddings_sample.h5\"\n",
        "\n",
        "data = load_data(hdf5_path, verbose=VERBOSE)\n",
        "\n",
        "# parse sentences\n",
        "pars_sentences = parse_sentences(data[\"sentences\"], verbose=VERBOSE)\n",
        "\n",
        "# encode triplets\n",
        "labels, mappings = encode_triplets(pars_sentences[\"triplets\"], verbose=VERBOSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndXQspjMRTd9",
        "outputId": "1f31aa4a-9883-4f6d-99f0-02fd83df9cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================\n",
            "Processing layer_8\n",
            "====================\n",
            "\n",
            "Training probe for object_1 classification (15 classes)...\n"
          ]
        }
      ],
      "source": [
        "# define layer name and process layer_data\n",
        "layer_name = \"layer_8\"\n",
        "layer_data = data[layer_name]\n",
        "\n",
        "if VERBOSE:\n",
        "    print(f\"\\n{'='*20}\")\n",
        "    print(f\"Processing {layer_name}\")\n",
        "    print(f\"{'='*20}\")\n",
        "\n",
        "# prepare layer_data split\n",
        "split_data = prepare_data_split(layer_data, pars_sentences[\"valid_indices\"], labels, test_size=0.2)\n",
        "\n",
        "# create data loaders\n",
        "data_loaders = create_data_loaders(split_data, batch_size=1024)\n",
        "\n",
        "# define component and input/output dimensions for training and hyper-param tuning\n",
        "component = \"object_1\"\n",
        "input_dim = layer_data.shape[1]\n",
        "num_classes = len(mappings[component])\n",
        "\n",
        "if VERBOSE:\n",
        "    print(f\"\\nTraining probe for {component} classification ({num_classes} classes)...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "Bj1lc_JKRpIg",
        "outputId": "669086dd-ff9f-4ec2-8794-fb5fe6d9ee92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcmoyacal\u001b[0m (\u001b[33mcmoyacal-purdue-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250226_085951-okczv38j</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna/runs/okczv38j' target=\"_blank\">sleek-sun-5</a></strong> to <a href='https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna' target=\"_blank\">https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna/runs/okczv38j' target=\"_blank\">https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna/runs/okczv38j</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# make the objective for optuna hyper-param tuning given component and layer\n",
        "\n",
        "# define train and test loaders\n",
        "train_loader = data_loaders[\"train\"][component]\n",
        "test_loader = data_loaders[\"test\"][component]\n",
        "\n",
        "# initialize weights & biases\n",
        "wandb.login()\n",
        "wandb.init(project=\"mlp-probe-optuna\", entity=\"cmoyacal-purdue-university\")\n",
        "\n",
        "# create specialized objective function for optuna\n",
        "objective = make_objective(input_dim, num_classes, train_loader, test_loader, epochs=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "OSo_5r4SeahA",
        "outputId": "d250c64a-8e27-4670-bc04-9efcb4881cb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-26 08:59:52,850] A new study created in memory with name: no-name-91df47ad-d891-4a95-9462-5dead7fb5a1f\n",
            "[I 2025-02-26 09:00:01,971] Trial 0 finished with value: 0.0010572602550382726 and parameters: {'depth': 2, 'width': 144, 'learning_rate': 0.009106830531136447}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:03,898] Trial 1 finished with value: 2.2524874210357666 and parameters: {'depth': 3, 'width': 18, 'learning_rate': 0.0006593677919262046}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:05,714] Trial 2 finished with value: 2.2123638838529587 and parameters: {'depth': 5, 'width': 35, 'learning_rate': 0.0004557516309649238}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:09,704] Trial 3 finished with value: 0.00711760253761895 and parameters: {'depth': 3, 'width': 168, 'learning_rate': 0.0027979474929474895}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:11,279] Trial 4 finished with value: 1.335129700601101 and parameters: {'depth': 2, 'width': 32, 'learning_rate': 0.0008464467007304086}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:16,664] Trial 5 finished with value: 2.1491140350699425 and parameters: {'depth': 5, 'width': 188, 'learning_rate': 0.00014009979853762264}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:18,418] Trial 6 finished with value: 0.4781826436519623 and parameters: {'depth': 5, 'width': 25, 'learning_rate': 0.007427611664098875}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:20,422] Trial 7 finished with value: 2.6688473969697952 and parameters: {'depth': 4, 'width': 54, 'learning_rate': 0.00010169435311598284}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:22,490] Trial 8 finished with value: 0.003570557091734372 and parameters: {'depth': 2, 'width': 53, 'learning_rate': 0.008351131484001365}. Best is trial 0 with value: 0.0010572602550382726.\n",
            "[I 2025-02-26 09:00:28,726] Trial 9 finished with value: 0.2830679537728429 and parameters: {'depth': 5, 'width': 226, 'learning_rate': 0.006948331819429152}. Best is trial 0 with value: 0.0010572602550382726.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▃▂█▇▃▇▁█▇</td></tr><tr><td>depth</td><td>▁▃█▃▁██▆▁█</td></tr><tr><td>learning_rate</td><td>█▁▁▃▂▁▇▁▇▆</td></tr><tr><td>loss</td><td>▁▇▇▁▅▇▂█▁▂</td></tr><tr><td>trial</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>width</td><td>▅▁▂▆▁▇▁▂▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>89.7</td></tr><tr><td>depth</td><td>5</td></tr><tr><td>learning_rate</td><td>0.00695</td></tr><tr><td>loss</td><td>0.28307</td></tr><tr><td>trial</td><td>9</td></tr><tr><td>width</td><td>226</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sleek-sun-5</strong> at: <a href='https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna/runs/okczv38j' target=\"_blank\">https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna/runs/okczv38j</a><br> View project at: <a href='https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna' target=\"_blank\">https://wandb.ai/cmoyacal-purdue-university/mlp-probe-optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250226_085951-okczv38j/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'depth': 2, 'width': 144, 'learning_rate': 0.009106830531136447}\n"
          ]
        }
      ],
      "source": [
        "#@title run optuna optimization\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# log best results to W&B\n",
        "wandb.config.update(study.best_params)\n",
        "wandb.finish()\n",
        "\n",
        "print(\"Best hyperparameters:\", study.best_params)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
