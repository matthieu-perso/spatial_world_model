# -*- coding: utf-8 -*-
"""inverse-relation-100k.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y5SYUDKexqkZelHMAFrpP4yVwP0Nx3aG

## setup
"""

import einops
import h5py
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import random
import re
import time
import torch

from dataclasses import dataclass
from google.colab import drive
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tabulate import tabulate
from torch import Tensor
from torch.utils.data import DataLoader, TensorDataset
from tqdm import tqdm
from typing import Dict, List, Tuple

"""## utils"""

# ==================
# function: set seed
# ==================
def set_seed(seed: int = 42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # for multi-GPU setups
    np.random.seed(seed)
    random.seed(seed)

    # ensures deterministic operations on GPU
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False  # Disable benchmark mode


# =================================
# function: extract representations
# =================================
def get_directions(linear_probe: torch.Tensor, options: int, mappings: Dict[str, int], verbose: bool=True) -> Dict[str, torch.Tensor]:
    """
    extract directions (unormalized) from linear probe
    """
    directions = linear_probe.detach().cpu().numpy()
    mapping = mappings["relation"]

    # create a mapping from class names to their weight vectors
    directions_dict = {}
    for relation, relation_index in mapping.items():
        if relation_index < options:
            directions_dict[relation] = directions[:, int(relation_index)]

    print(f"shape of direction vector (d_model,) = {directions_dict['above'].shape}" if verbose else "")

    return directions_dict

# =================================
# function: compute inverse metrics
# =================================
def compute_inverse_metrics(vec1: np.ndarray, vec2: np.ndarray) -> Tuple[float, float, float]:
    """Compute cosine similarity, Euclidean distance, and angle (in degrees) between vec1 and -vec2."""
    cosine_sim = cosine_similarity([vec1], [-vec2])[0][0]
    euclidean_dist = np.linalg.norm(vec1 - vec2)
    angle_deg = np.degrees(np.arccos(np.clip(cosine_sim, -1.0, 1.0)))
    return cosine_sim, euclidean_dist, angle_deg

# ==============================
# function: plot PCA projections
# ==============================
def plot_pca_projections(W_2d, relation_names, title="PCA Projection", ax=None):
    colors = plt.colormaps["tab10"]
    if ax is None:
        fig, ax = plt.subplots(figsize=(8, 6))
    for i, rel in enumerate(relation_names):
        x, y = W_2d[i]
        ax.scatter(x, y, color=colors(i % 10), s=100, label=rel)
        ax.text(x + 0.03, y + 0.03, rel, fontsize=11)
    ax.set_title(title)
    ax.set_xlabel("PC1")
    ax.set_ylabel("PC2")
    ax.grid(True)
    ax.legend()

# ==================================
# function: plot decision boundaries
# ==================================
def plot_decision_boundary(vec, W_2d, relation_names, title, ax):
    x_min, x_max = -10, 10
    y_min, y_max = -10, 10
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),
                         np.linspace(y_min, y_max, 300))
    grid = np.c_[xx.ravel(), yy.ravel()]
    decision_vals = grid.dot(vec).reshape(xx.shape)

    ax.contourf(xx, yy, decision_vals > 0, alpha=0.3, cmap=plt.cm.Paired)
    ax.contour(xx, yy, decision_vals, levels=[0], colors='k', linewidths=2)
    plot_pca_projections(W_2d, relation_names, title=title, ax=ax)

# ===============================
# function: print inverse summary
# ===============================
def print_inverse_summary(df: pd.DataFrame):
    print("\nðŸ“Š Inverse Relation Metrics Summary")
    print(tabulate(df, headers="keys", tablefmt="github", floatfmt=".4f"))

    print("\nðŸ“ˆ Summary Statistics (Mean)")
    mean_stats = df[['Cosine Similarity', 'Euclidean Distance', 'Angle (Â°)']].mean().to_frame().T
    print(tabulate(mean_stats, headers="keys", tablefmt="github", floatfmt=".4f"))

    print("\nðŸ“ Inverse Pairs Sorted by Angle (Descending)")
    sorted_df = df.sort_values("Angle (Â°)", ascending=False)[['Relation 1', 'Relation 2 (Inverse)', 'Angle (Â°)']]
    print(tabulate(sorted_df, headers="keys", tablefmt="github", floatfmt=".2f"))

# ================================
# function: check inverse relation
# ================================
def check_inverse_relations(directions: Dict[str, np.ndarray], verbose=True) -> pd.DataFrame:
    """
    Check inverse relations between binary spatial relation probe vectors.
    Returns a DataFrame and displays PCA visualizations and decision boundaries.
    """
    binary_spatial_relations = [
        ("above", "below"),
        ("to the left of", "to the right of"),
    ]

    results = []
    for rel1, rel2 in binary_spatial_relations:
        if rel1 in directions and rel2 in directions:
            vec1, vec2 = directions[rel1], directions[rel2]
            cos_sim, dist, angle = compute_inverse_metrics(vec1, vec2)
            results.append({
                'Relation 1': rel1,
                'Relation 2 (Inverse)': rel2,
                'Cosine Similarity': cos_sim,
                'Euclidean Distance': dist,
                'Angle (Â°)': angle
            })
            if verbose:
                print(f"\nðŸ” Inverse Pair: '{rel1}' â†” '{rel2}'")
                print(f"  Cosine Similarity: {cos_sim:.4f}")
                print(f"  Angle: {angle:.2f}Â°")

    df = pd.DataFrame(results)
    if not df.empty and verbose:
        print_inverse_summary(df)

    # === PCA ===
    relation_names = list(directions.keys())
    W = np.stack([directions[r] for r in relation_names])
    pca = PCA(n_components=2)
    W_2d = pca.fit_transform(W)

    fig, ax = plt.subplots(figsize=(8, 6))
    plot_pca_projections(W_2d, relation_names, ax=ax)
    plt.tight_layout()
    plt.show()

    # PCA Inverse Metrics & Decision Boundaries
    for rel1, rel2 in binary_spatial_relations:
        if rel1 in directions and rel2 in directions:
            i1, i2 = relation_names.index(rel1), relation_names.index(rel2)
            vec1_pca, vec2_pca = W_2d[i1], W_2d[i2]
            cos_sim_2d, _, angle_deg_2d = compute_inverse_metrics(vec1_pca, vec2_pca)

            if verbose:
                print(f"\nðŸ§­ PCA Inverse Pair: '{rel1}' â†” '{rel2}'")
                print(f"  PCA Cosine Similarity: {cos_sim_2d:.4f}")
                print(f"  PCA Angle: {angle_deg_2d:.2f}Â°")

            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
            plot_decision_boundary(vec1_pca, W_2d, relation_names, f"Boundary for '{rel1}'", ax1)
            plot_decision_boundary(-vec2_pca, W_2d, relation_names, f"Boundary for -'{rel2}'", ax2)
            plt.tight_layout()
            plt.show()

    return df

"""## data utils"""

# =========================
# function: parse sentences
# =========================
def parse_sentences(
    sentences: List[str],
    verbose: bool = True,
    num_sample_triplets: int = 100
) -> Dict[str, List]:
    """
    Parses sentences into structured triplets with precise relation extraction.
    """
    start_time = time.time()

    triplets = []
    valid_indices = []

    # Updated regex pattern to capture the full multi-word relation
    pattern = r"The\s+(.*?)\s+is\s+(.*)\s+the\s+(.*?)\."

    for i, sentence in enumerate(sentences):
        # decode the byte string to a regular string
        sentence = sentence.decode('utf-8')
        match = re.match(pattern, sentence, re.IGNORECASE)
        if match:
            obj1 = match.group(1).strip()
            relation = match.group(2).strip()
            obj2 = match.group(3).strip()
            triplets.append((obj1, relation, obj2))
            valid_indices.append(i)

    if verbose:
        print("\n=== triplets ===")
        for i in range(min(num_sample_triplets, len(triplets))):
            print(f"{i}: {triplets[i]}")

    return {
        "triplets": triplets,
        "valid_indices": valid_indices
    }

# =========================
# function: encode triplets
# =========================
def encode_triplets(
    triplets: List[Tuple[str, str, str]],
    verbose: bool = True
) -> Tuple[Dict[str, np.ndarray], Dict[str, Dict[str, int]]]:
    """
    encode triplets for model training
    """
    start_time = time.time()
    print("encoding triplets..." if verbose else "")

    # extract separate components
    objects1, relations, objects2 = zip(*triplets)

    # filter out empty strings
    objects1 = [obj if obj else "UNKNOWN" for obj in objects1]
    relations = [rel if rel else "UNKNOWN" for rel in relations]
    objects2 = [obj if obj else "UNKNOWN" for obj in objects2]

    # encode each component
    obj1_encoder = LabelEncoder()
    rel_encoder = LabelEncoder()
    obj2_encoder = LabelEncoder()

    obj1_labels = obj1_encoder.fit_transform(objects1)
    rel_labels = rel_encoder.fit_transform(relations)
    obj2_labels = obj2_encoder.fit_transform(objects2)

    labels = {"object_1": obj1_labels, "relation": rel_labels, "object_2": obj2_labels}

    # create mapping dictionaries for later analysis
    obj1_mapping = dict(zip(obj1_encoder.classes_, range(len(obj1_encoder.classes_))))
    rel_mapping = dict(zip(rel_encoder.classes_, range(len(rel_encoder.classes_))))
    obj2_mapping = dict(zip(obj2_encoder.classes_, range(len(obj2_encoder.classes_))))

    mappings = {"object_1": obj1_mapping, "relation": rel_mapping, "object_2": obj2_mapping}

    if verbose:
        print(f"found {len(obj1_mapping)} unique objects as subject")
        print(f"found {len(rel_mapping)} unique relations")
        print(f"found {len(obj2_mapping)} unique objects as object")

        # Print some of the unique relations
        print("\nrelations used:")
        sample_relations = list(rel_mapping.keys())
        for i, rel in enumerate(sample_relations):
            print(f"{i}: {rel}")

        print(f"encoding completed in {time.time() - start_time:.2f} seconds")

    return labels, mappings

# ============================
# function: prepare data split
# ============================
def prepare_data_split(layer_data: torch.Tensor, valid_indices: List[int], labels: Dict[str, np.ndarray], test_size: float=0.2) -> Dict[str, torch.Tensor]:
    """
    prepare single train/test split for all labels
    """
    # filter embeddings to keep only valid indices
    X = layer_data[valid_indices]

    # create a single train/test split for all labels
    X_train, X_test, y_rel_train, y_rel_test = train_test_split(
        X,
        labels["relation"],
        test_size=test_size,
        random_state=42
        )

    # convert to PyTorch tensors
    X_train_tensor = X_train.clone().detach().float()
    X_test_tensor = X_test.clone().detach().float()

    y_rel_train_tensor = torch.tensor(y_rel_train, dtype=torch.long)
    y_rel_test_tensor = torch.tensor(y_rel_test, dtype=torch.long)

    return {
        'X_train': X_train_tensor,
        'X_test': X_test_tensor,
        'y_rel_train': y_rel_train_tensor,
        'y_rel_test': y_rel_test_tensor,
        }


# =============================
# function: create data loaders
# =============================
def create_data_loaders(split_data: Dict[str, torch.Tensor], batch_size: int=256) -> Dict[str, Dict[str, TensorDataset]]:
    """
    create data loaders for training and testing
    """
    # create training dataset
    train_rel_dataset = TensorDataset(split_data['X_train'], split_data['y_rel_train'])

    # create test dataset
    test_rel_dataset = TensorDataset(split_data['X_test'], split_data['y_rel_test'])

    # create data loaders
    train_rel_loader = DataLoader(train_rel_dataset, batch_size=batch_size, shuffle=True)
    test_rel_loader = DataLoader(test_rel_dataset, batch_size=batch_size)

    return {
        'train': {
            'relation': train_rel_loader,
            },
        'test': {
            'relation': test_rel_loader,
            }
        }

"""## linear probes"""

# ============================
# class: probe train arguments
# ============================
@dataclass
class ProbeTrainingArgs:
    verbose: bool = False
    device: torch.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # layer information
    layer_name: str = "layer_8"

    # spatial relation state
    options: int = 4
    d_model: int = 3072

    # standard training hyperparams
    epochs: int = 10

    # hyperparams for optimizer
    lr: float = 1e-3

    # cpde to get randomly initialized probe
    def setup_probe(self) -> torch.Tensor:
        linear_probe = torch.randn(self.d_model, self.options, device=self.device) / np.sqrt(self.d_model)
        linear_probe.requires_grad = True
        print(f"shape of linear probe is: d_model = {linear_probe.shape[0]} and options = {linear_probe.shape[-1]}" if self.verbose else "")
        return linear_probe

# ===========================
# class: Linear probe trainer
# ===========================
class LinearProbeTrainer:
    def __init__(self, args: ProbeTrainingArgs, dataloader: torch.utils.data.DataLoader):
        self.args = args
        self.linear_probe = args.setup_probe()
        self.dataloader = dataloader

    def train(self):
        if self.args.verbose:
            print(f"\ntraining a linear probe for spatial relations of layer {self.args.layer_name} for {self.args.epochs} epochs ...\n")
        self.step = 0

        # define optimizer
        optimizer = torch.optim.Adam(
            [self.linear_probe], lr=self.args.lr
        )

        # define loss criterion
        criterion = torch.nn.CrossEntropyLoss()

        for epoch in range(self.args.epochs):
            total_loss = 0
            correct = 0
            total = 0

            for inputs, targets in tqdm(self.dataloader, desc=f"Epoch {epoch+1}/{self.args.epochs}"):

                # move data to device
                inputs, targets = inputs.to(self.args.device), targets.to(self.args.device)

                # get probe output
                probe_preds = einops.einsum(
                    inputs,
                    self.linear_probe,
                    "batch d_model, d_model options -> batch options",
                    )

                # compute loss
                loss = criterion(probe_preds, targets)

                # optimize
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()

                # update loss and accuracy
                total_loss += loss.item()
                _, predicted = torch.max(probe_preds.data, 1)
                total += targets.size(0)
                correct += (predicted == targets).sum().item()

            # print epoch results
            avg_loss = total_loss / len(self.dataloader)
            accuracy = 100 * correct / total
            print(f"Epoch {epoch+1}/{self.args.epochs}: Loss={avg_loss:.4f}, Accuracy={accuracy:.2f}%")

# ========================
# function: evaluate probe
# ========================
def evaluate_probe(linear_probe: torch.Tensor, dataloader: DataLoader, device=torch.device("cuda" if torch.cuda.is_available() else "cpu")):
    """
    evaluate a linear probe model
    """
    all_preds = []
    all_targets = []

    with torch.inference_mode():
        for inputs, targets in dataloader:

            # move data to device
            inputs, targets = inputs.to(device), targets.to(device)

            # get linear probe preds
            probe_preds = einops.einsum(
                inputs,
                linear_probe,
                "batch d_model, d_model options -> batch options",
                )
            _, predicted = torch.max(probe_preds, 1)

            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

    accuracy = accuracy_score(all_targets, all_preds)
    report = classification_report(all_targets, all_preds, output_dict=True, zero_division=1)

    return accuracy, report

"""## main"""

# mount google drive
drive.mount('/content/drive')

# config variables
VERBOSE = True
selected_layer: int = 24

# define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"we are using {device}" if VERBOSE else "")

# seet rng seed
set_seed(1234)

# define the dataset name
dataset_path = "drive/MyDrive/datasets-sentences/simple_atomic_100488_sentences.h5"

# load the data
dataset = h5py.File(dataset_path, 'r')

# list the datasets (for example, "sentences" and possibly an "embeddings" group)
print(list(dataset.keys()))

# define sentences and embeddings
sentences = dataset['sentences']
embeddings = dataset['embeddings']
layers_list = [8, 16, 24]

if VERBOSE:
    print("\n" + "=" * 40)
    print("ðŸ“Š dataset and embedding statistics")
    print("=" * 40)

    # dataset statistics
    print(f"\nðŸ”¢ dataset overview:")
    print(f"â€¢ total sentences: {len(sentences):,}")

    # layer details
    print(f"\nðŸ§¬ embedding layers extracted:")
    for k in layers_list:
        layer_name = f"layer_{k}"
        layer_shape = embeddings[layer_name].shape
        print(f"â€¢ layer {k}: shape: {layer_shape}")
    print("\n" + "=" * 40)

"""## training linear probes"""

# transform data to torch
layers_tensors = {}
for k in layers_list:
    layer_name = f"layer_{k}"
    layers_tensors[layer_name] = torch.tensor(embeddings[layer_name][:])
    print(f"layer {k} embeddings shape (# sentences, d_model): {layers_tensors[layer_name].shape}" if VERBOSE else "")

# parse senteces
pars_sentences = parse_sentences(sentences, verbose=VERBOSE, num_sample_triplets=20)

# encode triplets
labels, mappings = encode_triplets(pars_sentences["triplets"], verbose=VERBOSE)

# prepare layer data for split
batch_size = {}
dataloaders = {}
test_size = 0.2

# get number of relations
options = len(mappings["relation"])
print(f"number of unique relations: {options}" if VERBOSE else "")

for k in layers_list:
    layer_name = f"layer_{k}"
    batch_size[layer_name], d_model = layers_tensors[layer_name].shape
    print(f"layer data shape (num, d_model): {layers_tensors[layer_name].shape}" if VERBOSE else "")

    # create dataloaders
    split_data = prepare_data_split(layers_tensors[layer_name], pars_sentences["valid_indices"], labels, test_size=test_size)
    dataloaders[layer_name] = create_data_loaders(split_data, batch_size=1024)

"""### train linear probes"""

# train the linear probe
torch.set_grad_enabled(True)
args = {}
trainers = {}

for k in layers_list:
    layer_name = f"layer_{k}"
    args[layer_name] = ProbeTrainingArgs(
        d_model=d_model,
        options=options,
        layer_name=layer_name,
        epochs=100,
        lr=1e-3,
        verbose=VERBOSE
        )

    trainers[layer_name] = LinearProbeTrainer(args[layer_name], dataloader=dataloaders[layer_name]["train"]["relation"])      # we focus only on the spatial relation
    trainers[layer_name].train()

"""## evaluate linear probes"""

# report accuracy
accuracy = {}
report = {}

for k in layers_list:
    layer_name = f"layer_{k}"
    accuracy[layer_name], report[layer_name] = evaluate_probe(trainers[layer_name].linear_probe, dataloaders[layer_name]["test"]["relation"], device=device)
    print(f"Linear probe accuracy: {accuracy[layer_name]:.4f}" if VERBOSE else "")

# extract the directions of each spatial relation as a Dict
directions = {}

for k in layers_list:
    layer_name = f"layer_{k}"
    directions[layer_name] = get_directions(trainers[layer_name].linear_probe, options, mappings, verbose=VERBOSE)  # each direction has shape (d_model,)

# check directions' properties
directions_df = {}

for k in layers_list:
    layer_name = f"layer_{k}"
    print(f"\ninverse relation analysis for layer {k}...")
    directions_df[layer_name] = check_inverse_relations(directions[layer_name])

