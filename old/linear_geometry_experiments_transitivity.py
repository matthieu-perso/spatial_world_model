# -*- coding: utf-8 -*-
"""linear-geometry-experiments-transitivity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/136f4lNj3luOedVG8ZcjyIN1JxkquZ3W4

## setup
"""

import einops
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import re
import random
import time
import torch

from dataclasses import dataclass
from itertools import permutations
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch import Tensor
from torch.utils.data import DataLoader, TensorDataset
from transformers import AutoTokenizer, AutoModelForCausalLM
from tqdm import tqdm
from typing import Dict, List, Tuple


VERBOSE = True
hf_token = userdata.get('HF_TOKEN')

# define objects
all_objects = [
    "book", "mug", "lamp", "phone", "remote", "cushion", "plate", "plate", "notebook", "pen", "cup",
    "clock", "chair", "table", "keyboard", "mouse", "bottle", "plant", "vase", "wallet", "bag", "shoe",
    # "hat", "pencil", "eraser", "folder", "speaker", "picture", "mirror", "pillow", "blanket", "carpet",
    #"painting", "flower", "stapler", "calculator", "projector", "monitor", "printer", "scanner",
    # "microphone", "camera", "laptop", "tablet", "mousepad", "desk", "couch", "sofa", "bed", "dresser",
    #"wardrobe", "bookshelf", "stool", "bench", "armchair",
    #"recliner",  "footstool", "rug", "curtain", "chandelier", "lamp", "candle",
]

# split train and test objects
num_train = int(1.0 * len(all_objects))
num_test = len(all_objects) - num_train

train_objects = all_objects[:num_train]
test_objects = all_objects[num_train:]

composition_relations = {
    "diagonally above and to the right of": ("above", "to the right of"),
    "diagonally above and to the left of": ("above", "to the left of"),
    "diagonally below and to the right of": ("below", "to the right of"),
    "diagonally below and to the left of": ("below", "to the left of")
}

# define train sentences
train_chained_sentences, train_direct_sentences = generate_transitivity_datasets(train_objects, composition_relations, verbose=VERBOSE)

# extract hidden states for training sentences
layers_list = [8, 16, 24]

# define the model and tokenizer
model_name = "meta-llama/Llama-3.2-3B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    token=hf_token,
    output_hidden_states=True,
    return_dict_in_generate=True,
    device_map="auto"
)
model.eval()

idx_break = None   # int for debugging (None if not)

# get embeddings for training linear-probe
random.shuffle(train_chained_sentences)
random.shuffle(train_direct_sentences)

chained_sentences, train_chained_embeddings = extract_embeddings(
    train_chained_sentences,
    model,
    tokenizer,
    layers_list=layers_list,
    verbose=VERBOSE,
    idx_break=idx_break
    )



direct_sentences, train_direct_embeddings = extract_embeddings(
    train_direct_sentences,
    model,
    tokenizer,
    layers_list=layers_list,
    verbose=VERBOSE,
    idx_break=idx_break
    )

"""# training linear probes

"""

# define layer
selected_layer: int = 24

# define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"we are using {device}" if VERBOSE else "")

# seet rng seed
set_seed(1234)

# transform data to pytorch
layer_name = f"layer_{selected_layer}"
layer_tensor_chained: Tensor = torch.tensor(train_chained_embeddings[layer_name][:])
print(f"layer {selected_layer} embeddings (chained) shape (# sentences, d_model): {layer_tensor_chained.shape}")

layer_tensor_direct: Tensor = torch.tensor(train_direct_embeddings[layer_name][:])
print(f"layer {selected_layer} embeddings (direct) shape (# sentences, d_model): {layer_tensor_direct.shape}")

# parse chained senteces
pars_chained_sentences = parse_chained_sentences(chained_sentences, verbose=VERBOSE, num_sample_quintuples=20)

# parse direct sentences
pars_direct_sentences = parse_sentences(direct_sentences, verbose=VERBOSE, num_sample_triplets=20)

# encode quituples
chained_labels, chained_mappings = encode_quintuples(pars_chained_sentences["quintuples"], verbose=VERBOSE)

# encode triplets
direct_labels, direct_mappings = encode_triplets(pars_direct_sentences["triplets"], verbose=VERBOSE)

# prepare layer data for split
batch_size_chained, d_model_chained = layer_tensor_chained.shape
print(f"layer data shape (num, d_model): {layer_tensor_chained.shape}" if VERBOSE else "")

# get number of relations
options_1 = len(chained_mappings["relation_1"])
print(f"number of unique relations 1: {options_1}" if VERBOSE else "")
options_2 = len(chained_mappings["relation_2"])
print(f"number of unique relations 2: {options_2}" if VERBOSE else "")

# create data loadersthe
test_size = 0.2
split_data_chained = prepare_data_split_chained(layer_tensor_chained, pars_chained_sentences["valid_indices"], chained_labels, test_size=test_size)
dataloaders_chained = create_data_loaders_chained(split_data_chained, batch_size=1024)

# prepare layer data for split
batch_size_direct, d_model_direct = layer_tensor_direct.shape
print(f"layer data shape (num, d_model): {layer_tensor_direct.shape}" if VERBOSE else "")

# get number of relations
options = len(direct_mappings["relation"])
print(f"number of unique relations: {options}" if VERBOSE else "")

# create data loadersthe
test_size = 0.2
split_data_direct = prepare_data_split(layer_tensor_direct, pars_direct_sentences["valid_indices"], direct_labels, test_size=test_size)
dataloaders_direct = create_data_loaders(split_data_direct, batch_size=1024)

# train the linear probe for relation 1 - chained
torch.set_grad_enabled(True)

args_rel_1 = ProbeTrainingArgs(
    d_model=d_model_chained,
    options=options_1,
    layer_name=layer_name,
    epochs=100,
    lr=1e-3,
    verbose=VERBOSE,
    )

trainer_rel_1 = LinearProbeTrainer(args_rel_1, dataloader=dataloaders_chained["train"]["relation_1"])      # we focus only on the spatial relation
trainer_rel_1.train()

# evaluate for relation 1
# report accuracy
accuracy_rel_1, report_rel_1 = evaluate_probe(trainer_rel_1.linear_probe, dataloaders_chained["test"]["relation_1"], device=device)
print(f"Linear probe accuracy: {accuracy_rel_1:.4f}" if VERBOSE else "")

# train the linear probe for relation 2 - chained
torch.set_grad_enabled(True)

args_rel_2 = ProbeTrainingArgs(
    d_model=d_model_chained,
    options=options_2,
    layer_name=layer_name,
    epochs=100,
    lr=1e-3,
    verbose=VERBOSE,
    )

trainer_rel_2 = LinearProbeTrainer(args_rel_2, dataloader=dataloaders_chained["train"]["relation_2"])      # we focus only on the spatial relation
trainer_rel_2.train()

# evaluate for relation 2
# report accuracy
accuracy_rel_2, report_rel_2 = evaluate_probe(trainer_rel_2.linear_probe, dataloaders_chained["test"]["relation_2"], device=device)
print(f"Linear probe accuracy: {accuracy_rel_2:.4f}" if VERBOSE else "")

# train the linear probe for relation - direct
torch.set_grad_enabled(True)

args_rel_direct = ProbeTrainingArgs(
    d_model=d_model_direct,
    options=options,
    layer_name=layer_name,
    epochs=100,
    lr=1e-3,
    verbose=VERBOSE,
    )

trainer_rel_direct = LinearProbeTrainer(args_rel_direct, dataloader=dataloaders_direct["train"]["relation"])      # we focus only on the spatial relation
trainer_rel_direct.train()

# evaluate for relation 3
# report accuracy
accuracy_rel_direct, report_rel_direct = evaluate_probe(trainer_rel_direct.linear_probe, dataloaders_direct["test"]["relation"], device=device)
print(f"Linear probe accuracy: {accuracy_rel_direct:.4f}" if VERBOSE else "")

# extract directions for chained and direct
directions_rel_1 = get_directions(trainer_rel_1.linear_probe, options_1, chained_mappings, relation_name="relation_1", verbose=VERBOSE)  # each direction has shape (d_model,)
directions_rel_2 = get_directions(trainer_rel_2.linear_probe, options_2, chained_mappings, relation_name="relation_2", verbose=VERBOSE)  # each direction has shape (d_model,)
directions_direct = get_directions(trainer_rel_direct.linear_probe, options, direct_mappings, verbose=VERBOSE)  # each direction has shape (d_model,)



# get transitivity properties
df_metrics = check_transitivity_relations(composition_relations, directions_rel_1, directions_rel_2, directions_direct, verbose=VERBOSE)

